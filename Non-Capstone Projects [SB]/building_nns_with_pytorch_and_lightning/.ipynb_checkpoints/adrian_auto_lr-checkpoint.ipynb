{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atlantic-approach",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- # The StatQuest Introduction to PyTorch Lightning!!! -->\n",
    "# The StatQuest Introduction to PyTorch + Lightning!!!\n",
    "<!-- # The StatQuest Introduction to Building Neural Networks with Lightning!!! -->\n",
    "## Sponsored by...\n",
    "[<img src=\"./images/Brandmark_FullColor_Black.png\" alt=\"Lightning\" style=\"width: 400px;\">](https://www.pytorchlightning.ai/)\n",
    "\n",
    "Copyright 2022, Joshua Starmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-skill",
   "metadata": {},
   "source": [
    "----\n",
    "**NOTE:** This tutorial is from the StatQuest **[A Gentle Introduction to Coding Neural Networks with Lightning]()**.\n",
    "\n",
    "In this tutorial, we will use **[Lightning](https://www.lightning.ai/)** to create, draw the output from, and optimize the super simple **neural network** featured in the StatQuest **[Neural Networks Part 3: ReLU in Action!!!](https://youtu.be/68BZ5f7P94E)** Specifically, we'll use **Lightning** to streamline the code we originally wrote in **PyTorch** in **[The StatQuest Introduction to PyTorch](https://youtu.be/FHdlXe1bSe4)**.  In that StatQuest, we implemented a simple neural network, seen below, that predicts whether or not a drug dose will be effective.\n",
    "<!-- <img src=\"./xgboost_tree.png\" alt=\"An XGBoost Tree\" style=\"width: 600px;\"> -->\n",
    "<img src=\"./images/simple_relu.001.png\" alt=\"A simple Neural Network\" style=\"width: 1620px;\">\n",
    "\n",
    "The training data (below) consist of three data points for three different drug doses. Low (**0**) and high (**1**) doses do not cure a disease, so their y-axis values are both **0**. However, when the dose is **0.5**, that dose can cure the disease, and the corresponding y-axis value is **1**.\n",
    "\n",
    "<img src=\"./images/training_data_500x275.png\" alt=\"A simple Neural Network\" style=\"width: 250px;\">\n",
    "\n",
    "Below, we see the output of the neural network for different doses, and it fits the training data well!\n",
    "\n",
    "<img src=\"./images/training_data_with_bent_shape_500x275.png\" alt=\"A simple Neural Network\" style=\"width: 250px;\">\n",
    "\n",
    "\n",
    "In this tutorial, you will...\n",
    "\n",
    "- **[Build a Simple Neural Network with Lightning](#build)**\n",
    "\n",
    "- **[Use the Neural Network and Graph the Output](#using)**\n",
    "\n",
    "- **[Optimize (Train) a Parameter in the Neural Network and Graph the Output](#train)**\n",
    "\n",
    "#### NOTE:\n",
    "This tutorial assumes that you already know the basics of coding in **Python** and are familiar with the <!-- basics of **[PyTorch](https://youtu.be/FHdlXe1bSe4)** and the  --> theory behind **[Neural Networks](https://youtu.be/CqOfi41LfDw)**, **[Backpropagation](https://youtu.be/IN2XmBhILt4)**, the **[ReLU Activation Function](https://youtu.be/68BZ5f7P94E)**, **[Gradient Descent](https://youtu.be/sDv4f4s2SB8)**, and **[Stochastic Gradient Descent](https://youtu.be/vMh0zPT0tLI)**. If not, check out the **'Quests** by clicking on the links for each topic.\n",
    "\n",
    "#### ALSO NOTE:\n",
    "I strongly encourage you to play around with the code. Playing with the code is the best way to learn from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-russian",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-arthritis",
   "metadata": {},
   "source": [
    "# Import the modules that will do all the work\n",
    "\n",
    "**TL;DR** This is the same as the **StatQuest: Introduction to PyTorch**, except now we are requiring at least **Python 3.8** and also importing **Lightning** and some utilities to manage the training data.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "The very first thing we need to do is load a bunch of Python modules. Python itself is just a basic programming language. These modules give us extra functionality to create a neural network, use and graph the output for various input values, and optimize the neural network's parameters.\n",
    "\n",
    "**NOTE:** You will need **Python 3.8** and have at least these versions for each of the following modules: \n",
    "- pytorch >= 1.10.1\n",
    "- matplotlib >= 3.3.4\n",
    "- seaborn >= 0.11.0 \n",
    "\n",
    "### If you installed **Python** with [Anaconda](https://www.anaconda.com/)...\n",
    "...then you can check which versions of each package you have with the command: `conda list`. If, for example, your version of `matplotlib` is older than **3.3.4**, then the easiest thing to do is just update all of your Anaconda packages with the following command: `conda update --all`. However, if you only want to update `matplotlib`, then you can run this command: `conda install matplotlib=3.3.4`.\n",
    "\n",
    "### If you need to install **PyTorch**...\n",
    "...then the easiest thing to do is follow the instructions on the [PyTorch website](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "### If you need to install **Lightning**...\n",
    "...then the easiest thing to do is follow the instructions on the [Lightning AI website](https://lightning.ai/lightning-docs/).\n",
    "\n",
    "\n",
    "### If you need to install **seaborn**...\n",
    "...then the easiest thing to do is follow the instructions on the [seaborn website](https://seaborn.pydata.org/installing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "warming-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # torch will allow us to create tensors.\n",
    "import torch.nn as nn # torch.nn allows us to create a neural network.\n",
    "import torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\n",
    "from torch.optim import SGD # optim contains many optimizers. Here, we're using SGD, stochastic gradient descent.\n",
    "\n",
    "from pytorch_lightning import Trainer, LightningModule # Trainer and LightningModule simplfy the code for backpropagation\n",
    "from torch.utils.data import TensorDataset, DataLoader # these are needed for the training data\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# import matplotlib.pyplot as plt ## matplotlib allows us to draw graphs.\n",
    "# import seaborn as sns ## seaborn makes it easier to draw nice-looking graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-guidance",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-confusion",
   "metadata": {},
   "source": [
    "<a id=\"build\"></a>\n",
    "# Build a Simple Neural Network in PyTorch\n",
    "\n",
    "Just like building a neural network in **PyTorch**, building a neural network in **PyTorch Lightning** means creating a new class with two methods: `__init__()` and `forward()`. The `__init__()` method defines and initializes all of the parameters that we want to use, and the `forward()` method tells **PyTorch Lightning** what should happen during a forward pass through the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "square-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a neural network class by creating a class that inherits from LightningModule\n",
    "class BasicLightning(LightningModule):\n",
    "\n",
    "    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n",
    "        \n",
    "        super().__init__() # initialize an instance of the parent class, nn.Model.\n",
    "        \n",
    "        ## Now create the weights and biases that we need for our neural network.\n",
    "        ## Each weight or bias is an nn.Parameter, which gives us the option to optimize the parameter by setting\n",
    "        ## requires_grad, which is short for \"requires gradient\", to True. Since we don't need to optimize any of these\n",
    "        ## parameters now, we set requires_grad=False.\n",
    "        ##\n",
    "        ## NOTE: Because our neural network is already fit to the data, we will input specific values\n",
    "        ## for each weight and bias. In contrast, if we had not already fit the neural network to the data,\n",
    "        ## we might start with a random initalization of the weights and biases.\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "        \n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "        self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, input): ## forward() takes an input value and runs it though the neural network \n",
    "                              ## illustrated at the top of this notebook. \n",
    "        \n",
    "        ## the next three lines implement the top of the neural network (using the top node in the hidden layer).\n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "        \n",
    "        ## the next three lines implement the bottom of the neural network (using the bottom node in the hidden layer).\n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "        \n",
    "        ## here, we combine both the top and bottom nodes from the hidden layer with the final bias.\n",
    "        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n",
    "        \n",
    "        output = F.relu(input_to_final_relu)\n",
    "    \n",
    "        return output # output is the predicted effectiveness for a drug dose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-retrieval",
   "metadata": {},
   "source": [
    "Once we have created the class that defines the neural network, we can create an actual neural network and print out its parameters, just to make sure things are what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fifth-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w00 tensor(1.7000)\n",
      "b00 tensor(-0.8500)\n",
      "w01 tensor(-40.8000)\n",
      "w10 tensor(12.6000)\n",
      "b10 tensor(0.)\n",
      "w11 tensor(2.7000)\n",
      "final_bias tensor(-16.)\n"
     ]
    }
   ],
   "source": [
    "## create the neural network. \n",
    "model = BasicLightning()\n",
    "\n",
    "## print out the name and value for each parameter\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-carrier",
   "metadata": {},
   "source": [
    "## BAM!!!\n",
    "The values for each weight and bias in `BasicNN` match the values we see in the optimized neural network (below).\n",
    "<img src=\"./images/simple_relu.001.png\" alt=\"A simple Neural Network\" style=\"width: 810px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-mouth",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-rings",
   "metadata": {},
   "source": [
    "<a id=\"using\"></a>\n",
    "# Use the Neural Network and Graph the Output\n",
    "\n",
    "Now that we have a neural network, we can use it on a variety of doses to determine which will be effective. Then we can make a graph of these data, and this graph should match the green bent shape fit to the training data that's shown at the top of this document. So, let's start by making a sequence of input doses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "induced-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "        0.9000, 1.0000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now create the different doses we want to run through the neural network.\n",
    "## torch.linspace() creates the sequence of numbers between, and including, 0 and 1.\n",
    "input_doses = torch.linspace(start=0, end=1, steps=11)\n",
    "\n",
    "# now print out the doses to make sure they are what we expect...\n",
    "input_doses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-cylinder",
   "metadata": {},
   "source": [
    "Now that we have `input_doses`, let's run them through the neural network and graph the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "understood-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the neural network. \n",
    "model = BasicLightning() \n",
    "\n",
    "## now run the different doses through the neural network.\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## Now draw a graph that shows the effectiveness for each dose.\n",
    "##\n",
    "## First, set the style for seaborn so that the graph looks cool.\n",
    "# sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "# sns.lineplot(x=input_doses, \n",
    "#              y=output_values, \n",
    "#              color='green', \n",
    "#              linewidth=2.5)\n",
    "\n",
    "# ## now label the y- and x-axes.\n",
    "# plt.ylabel('Effectiveness')\n",
    "# plt.xlabel('Dose')\n",
    "\n",
    "## optionally, save the graph as a PDF.\n",
    "# plt.savefig('BasicLightning.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-franchise",
   "metadata": {},
   "source": [
    "The graph shows that the neural network fits the training data. In other words, so far, we don't have any bugs in our code.\n",
    "# Double BAM!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-community",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-member",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "# Optimize (Train) a Parameter in the Neural Network and Graph the Output\n",
    "\n",
    "Now that we know how to create and use a simple neural network, and we can graph the output relative to the input, let's see how to train a neural network. The first thing we need to do is tell **Lightning** which parameter (or parameters) we want to train, and we do that by setting `requires_grad=True`. In this example, we'll train `final_bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "arbitrary-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a neural network class that we can train by creating a class that inherits from LightningModule\n",
    "##\n",
    "## NOTE: This new class, BasicLightningTrain, contains two new methods for training:\n",
    "##\n",
    "## training_step() - This method takes care of 4 things:\n",
    "##      a) calculates the loss for an epoch \n",
    "##      b) resets the gradients \n",
    "##      c) backpropagation \n",
    "##      d) updates the parameters\n",
    "## configure_optimizers() - defines the method we will use to optimize the model\n",
    "class BasicLightningTrain(LightningModule):\n",
    "\n",
    "    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n",
    "\n",
    "        ## NOTE: The code for __init__ () is the exame before except that we modified final_bias in two ways:\n",
    "        ##       1) we set the value of the tensor to 0, and\n",
    "        ##       2) we set \"requires_grad=True\".\n",
    "        \n",
    "        super().__init__() # initialize an instance of the parent class, LightningModule.\n",
    "        \n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "        \n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "        ## We want to modify final_bias to demonstrate how to optimize it with backpropagation.\n",
    "        ## NOTE: The optimal value for final_bias is -16...\n",
    "#         self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
    "        ## ...so we set it to 0 and tell Pytorch that it now needs to calculate the gradient for this parameter.\n",
    "        self.final_bias = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "        \n",
    "        self.learning_rate = 0.01\n",
    "        \n",
    "    def forward(self, input): \n",
    "        \n",
    "        ## forward() is the exact same as before\n",
    "        \n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "        \n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "        \n",
    "        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n",
    "        \n",
    "        output = F.relu(input_to_final_relu)\n",
    "    \n",
    "        return output # output is the predicted effectiveness for a drug dose.\n",
    "    \n",
    "    # def on_train_epoch_end(self):\n",
    "    #     print(self.final_bias, self.current_epoch)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ## NOTE: When training_step() is called it runs the code below...\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i)\n",
    "        loss = (output_i - label_i)**2 ## squared residual loss\n",
    "        self.log('val_loss', loss)\n",
    "        ##...before calling (internally and behind the scenes)...\n",
    "        ## optimizer.zero_grad() # to clear gradients\n",
    "        ## loss.backward() # to do the backpropagation\n",
    "        ## optimizer.step() # to update the parameters\n",
    "        # print(\"Step: \" + str(self.current_epoch) + \", Final Bias: \" + str(self.final_bias.data))\n",
    "#         print(loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n",
    "        return SGD(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-designation",
   "metadata": {},
   "source": [
    "Now let's graph the output of `BasicLightningTrain`, which is currently not optimized, and compare it to the graph we drew earlier of the optimized neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "above-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the neural network. \n",
    "model = BasicLightningTrain() \n",
    "\n",
    "## now run the different doses through the neural network.\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## Now draw a graph that shows the effectiveness for each dose.\n",
    "##\n",
    "## set the style for seaborn so that the graph looks cool.\n",
    "# sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "# sns.lineplot(x=input_doses, \n",
    "#              y=output_values.detach(), ## NOTE: because final_bias has a gradident, we call detach() \n",
    "#                                        ## to return a new tensor that only has the value and not the gradient.\n",
    "#              color='green', \n",
    "#              linewidth=2.5)\n",
    "\n",
    "# ## now label the y- and x-axes.\n",
    "# plt.ylabel('Effectiveness')\n",
    "# plt.xlabel('Dose')\n",
    "\n",
    "## lastly, save the graph as a PDF.\n",
    "# plt.savefig('BasicLightningTrain.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-discharge",
   "metadata": {},
   "source": [
    "The graph shows that when the dose is **0.5**, the output from the unoptimized neural network is **17**, which is wrong, since the output value should be **1**. So, now that we have a parameter we can optimize, let's create some training data that we can use to optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "annual-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training data for the neural network.\n",
    "inputs = torch.tensor([0., 0.5, 1.])\n",
    "labels = torch.tensor([0., 1., 0.])\n",
    "# inputs = torch.tensor([0., 0.5, 1.])\n",
    "# labels = torch.tensor([0., 1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48fca13a-066f-400b-8668-b87df0cb211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-control",
   "metadata": {},
   "source": [
    "...and now let's use that training data to train (or optimize) `final_bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "greater-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b885412a814541ab35ab6cd3924547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Restoring states from the checkpoint path at /Users/adrian/Documents/temp/.lr_find_c26ce5d2-7d9b-4eb2-8b0b-0bdbb077dc4c.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LR finder found the best learning rate is: 0.00214\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)  # batch_size=1\n",
    "model = BasicLightningTrain()\n",
    "\n",
    "trainer = Trainer(max_epochs=34)\n",
    "\n",
    "# Run learning rate finder\n",
    "lr_finder = trainer.tuner.lr_find(model, train_dataloaders=dataloader, min_lr=0.001, max_lr=1.0, early_stop_threshold=None)\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "print(f\"The LR finder found the best learning rate is: {new_lr:.05f}\")\n",
    "\n",
    "# update hparams of the model\n",
    "model.learning_rate = new_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd746993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/0cmn_hsd4ys18k3l6ks4gg_m0000gn/T/ipykernel_4114/1529364680.py:2: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4GElEQVR4nO3dd3xb5d3//9fH8t6J45HhLGdvQiAQQgIFShhllL3KalmlFOjNDfTXu+Pu927pYJSWsimUskqgZZWdkBASAllkQBKcve04Trxljev3xzmSJUt2nGBZts7n+Xj4QSwdSZd98FuXPucaYoxBKaWUcyTFuwFKKaW6lga/Uko5jAa/Uko5jAa/Uko5jAa/Uko5jAa/Uko5THK8G9ARffr0MYMHD453M5RSqkdZunTpXmNMYevbe0TwDx48mCVLlsS7GUop1aOIyJZot2upRymlHEaDXymlHEaDXymlHEaDXymlHEaDP5Y2bICbboLcXEhKsv57003W7UopFSca/LHy9tswYQI88QTU1oIx1n+feMK6/e23491CpZRDOTL4DzR42F7dELsX2LABzj8fGhrA4wm/z+Oxbj//fO35K6XiwpHBf9/767jyqc/aPWbRhipufXE57e1X4PMbvt5TG3nHvfdGBn5rHg/cf39HmquUUp3KkcFfVd/Mnhp3u8d8Ur6Xf6/Yyf6GtgP8/S/38O0H5rO1qtWnh3/8o2PB/+yzHW2yUkp1GkcGv9vrp87txedvuzff5PEBsKe2qc1j9tQ0YQx8XdGq119X17GG2Mc1eXxc8tinLNta3bHHKaXUN+DY4Aeoc3vbPKYxEPztfDKobbJ69Ztb9/izszvWEPu4rfsaWLSxije/2NXmocYYvvvXT3jxs60de26llGqDM4PfDvWaxrbLMU0e681hT03bPf7aJuuNY0tVffgdl18OKSntNyIlBa64AoAK+81lxba2e/w1TV6Wbd3Payt2tvu0d85eyUNzy9t/baWUozkz+O0efyC4owmUeiraCf4a+/Gb9rYK/p/8pGPBf9ttQMuby+qdNTTbbWtt5/5GAJZtrQ62rTVjDP9ZtYt/fLql3YvS76zexUuf6ycHpZzKkcHfHAz+tnv8h1Lq2dK61FNWBrNnQ2YmXlerBVBTUiAz07q/rAyAilp3sF1rd9dEfa1A8Lu9fr7Ytj/qMdUNHmrdXnYdaGL9nravMzw8byO/fvMr3N7obyBgvfFV1rZ/AVwp1TM5MvgDgVfTgR5/e6WewOO3VzdE9tRPOw1WruSTE8+lNjUTP4I3Oweuuw5WrrTut1XUNpEk1r9XtBHqO+zgB/h0476ox4SWnOatr4h6jDGGjRV11Lm9LNxQ1ebPdt/765n1wPx23xyUUj2TQ4P/EHr87fR6A4/3m/BgDior49ELb+eMX7/J0Dvf4Nl3voC//CXY0w+oqHEzqCCLwpw0lm/dH/W1duxvJNWVxKiSHBZvih7YgU8eOWnJzFtfGfWYilo3tfZF7ffW7G7zZ1u+tZqq+mbmrYv+PABVdW5eW7Gj3bKSUqr7cXjwtzOqp/ngNf7aJi9FOWkAbG59gde2r76ZEcU5FGSlsnZXlMleWD3+opw0JpXmt9nj37m/iX756Uwr68PSLdVRe+KB4D93cn8+31RNfZRRSxsqrBJQUU4a73+5J+qQVmMMa3dbbX1jZdsjjZ5ZtIUfv7iC1Tuil6eUUt2TM4Pf7s231+MPvDlU1LrxtzHev7bJw/j+eQBsbn2B11bd0ExBViqj+ua0Wb+vqHVTlJvOpNJ8Nu2tZ39Dc8QxO6ob6JefwTFDe9t1/gMRx2zZV0/fvHROHVtCs8/PoiilnA2VVvD/4Pih7K1rZnmUuQM7DzRR2+QlJz2ZD77cQ0Nz9DfIVdv3AzB76bao94NVVnttxY42f4dKqa7nzOC3Q729Gn+gx+/zG6rqI4MYrB7/kD5ZZKW6Ii/wYvWcq+s99MpKZVRJLuv21Eb0sI0x7KmxevxHlOYD0ev8Vo8/g6OH9EYEPt0YGepbqxoY2DuTKYN7kZnq4qModf4NlfVkpyVz0dGlpLiE977cE3HMOvsN6oaZZTR6fHz4VeTzGGNYZff0X/tiZ5vXAl5fsZMfv7iCt1e3XVZSSnUtxwW/MaZDNf4mr4+S3HQg+gVer89PQ7OPnPQUBvfJilrqqXN7afb56Z2VwqiSHJo8/ogx/7VuL00eP8W5aYwfkIdIZPB7fH721FrBn5+ZyuiS3KjBv2VfA4MKMklLdjGtrICP1lVG1N/LK+ooK8wiNz2FY8v68O6a3RHHfGWXpC6fOoji3DTe+CJy7sCeGjd769ycOLKQ/Q0e5kR5cwCCs5Gf/yzq1p9Bep1Aqa4T0+AXkdtEZI2IrBaRF0QkXUSGiMhiESkXkZdEJDWWbWit2dcy+uZgPf5BBZlA9OAPzPrNSU9mcEFW1B5/db31xtI7K43RfXMBgrXzgMDkraKcdHLSUxhelB0R/LsPWEtDDMjPAOCYoQURdf56t5fKWusiMcDMkUVsr26MmGOwobKOskJrxvCpY4vZUtUQMfRz3e5a+udnkJeZwhnj+/HRukoOtJrstmqHVWq6YWYZxblpzF66PeLnB1i2ZT8i8El5VeR8B9u2fQ2M/cW7zG/jgrRSqnPFLPhFpD9wCzDFGDMOcAEXA78D7jfGDAOqgWtj1YZo3CHDLtuauev3W58KWoI/cmRP4MJwTnoygwoy2bavAa8vfEjnPrtW3zsrhWFF2SQJrN0VXucPXDwuyrUuEk8qzeeLbfvDesCBEUP9gsEfWeffus964xnY22rzCSMKAfgoZFROnT3Gv6zICv5TRhcjAu+2Gt2zbncto0pyADhrUj+aff6IEUCrdhwgSWD8gDy+O3kAH62vpKLVukY1TR7WV9Ry6dEDSU4SXmhjuYl56ytpaPbx8Ee6TLVSXSHWpZ5kIENEkoFMYBfwLWC2ff8zwDkxbkOY0PH2bY3qCbw5BEI0Wo+/xi4TBUo9Xr+JGNK5r956w+iVmUp6iouhhdl81brHX9vS4weYVNqL6gZP2CeIncHgt44J1PlDL94Gjh9s9/hLe2cytDCLuetaSjCbKq0ed6DHX5SbzhGl+WHB3+z1s6GyjpF28E8ckEdp74yI0T2rdxygrDCbzNRkzps8AJ/f8Nry8JKQ9QYGp44t4dtji3l5ybaos44DZatFG6v4alfbI4Q2762PeHNVSh26mAW/MWYH8EdgK1bgHwCWAvuNMYHE3Q70j1UbonGHBX/0Hn9gDH92WjJ9slMjerLWY60fIdcu9UDkYm377FJPQZbVmx9VEjmyJ/DcoT1+gOUh6/bsqA7v8ednpjK2Xy4Lylt681v3WaE+0P6UAnDy6GI+3VgV/DkDI3qGFWUFjzl9fF/W7KwJlmE2VNbh9RtG2aUpEeGsif34pHxv2O9h1Y4DwRFNw4qyOWJgPrOXbg/7pBIo80wamM9lUwdR3eDhnVYXeY0xfLpxHyeOLCQ9JYmnP9lMNJW1br59/3zue3991PuVUh0Xy1JPL+BsYAjQD8gCZh3C468TkSUisqSysvNqv4GhnOkpSW3W+APBn5Hqoign/SClnhQG22Hb+sJttT0aqFeWtW7P6L65bNvXGPaGs6fGTUaKi5w0a2mHkSU5ZKcls2RzS/DvPNBIn2zrU0PAjOGFLNu6P/jJY3NVA/mZKeRltKwRdMqYYjw+Eyz3lFfU4UoSBvYOD36AN+0LuIE3pkCpB+DcI8J79HtqmqisdTPODn6A848cwLo9tWHXJ5ZtrWZ4UbZ1IXloAYMLMnlucfhF3g2V9eytc3Pq2BK+O3kA/1qxg6q6yN/3x19X0uzz8+yiLcGfWSl1eGJZ6jkZ2GSMqTTGeIBXgeOAfLv0AzAA2BHtwcaYx4wxU4wxUwoLCzutUYEef2FOWps9/qbgm4OL4ty0qKWe2mCpJ5nCnDQyU11s3tuqx9/QTIpLyA6EerEVputCyj3WGP40RKw1G1xJwpTBvVi8qWVZhh32UM5QM0YU4vMbFpZbZZKtVQ0M6p0Zdszkgb0oyErlfXvI5obKOgYVZJKa3HLa++VnMGVQL960Szlrd9eS6kpiSJ+WN4dhRdlMLM3nlWVWj37VduvawvgBLcF/1sR+ZKa6gnV8v9+wfGs1kwf2AiApSbh06kA+31wd9vMHyjzHDC3g6mmDafb6o14LmLe+kowUF7VuL88v1gXmlPomYhn8W4FjRCRTrFQ7CfgSmAucbx9zJfBaDNsQIRD8fbLTaPL48USpGQfG8FvBf7AefzIiwqCCyCGd++qa6ZWZGgz1Mf2s8smanS3lngp7DH+oo4f0pryijr12z3fn/kb6twr+yQN7kZXqYv7XVm9+y756BhZkhR3jShJOGl3E3HUVwdp9oL4f6jsT+7FuTy3r99SybnctZUXZpLjC/9c4f3J/1u6uZc3OGlbtOIAIjLHLQdbvIYWzJvbjjS92UdPkYePeOmqavMHgB7jgyFLSkpN4ZtHm4G2fbqyiJDedQQWZDC/O4fjhfXj20y1h58XnN8xfX8lp40qYPqwPTy3YFHXegDGGCx5ZqMtSK3UQsazxL8a6iLsMWGW/1mPAncDtIlIOFABPxqoN0QRKPX2yrbCNdoE3ECoZKS6KctOpqndHvEHUhlzcBRhckBkZ/A3N9M5qGa3aNy+dwpy0sNU1A7N2Q00dUgDA55v2YYxhR3VjRI8/NTmJY8v6MH99JR6fn537m4Ilp1CnjCmhtsnLwg172by3IWrwnza+hCSxyj1rd9UyOqTME/Cdif1IdSXxyrLtwQu7WWnhK49eOnUgjR4fry3fwbIt1s84eVB+8P5eWamcM6k/ry7bzoEGT7C+f8zQ3sE3x2uOG8KeGjdvhVxMXr3jANUNHmaOLOSGmWVU1Lr517LID4prdtbw+eZq/jKnPGq5SClliemoHmPML4wxo4wx44wxVxhj3MaYjcaYo40xw4wxFxhjuvQvNLTUA9GHdDY2W8ekp7goyU3HGIK974DaJi9pyUnBssmggiy27WsIm5lbXR8e/CLCxAF5fGEvdQDRe/zj++eRnpLE4k372N/godHjiwh+gJkj+rC9upEFX+/F5zfBUUihpg/rQ3pKEk99splmn5+ywqyIY4py0pk6pICXl25nd01TcERPqPzMVE4eU8RrK3byxfaWC7ut2z22Xy7PLd7Ksq3V5KYnM7RP+BvNldMG0+Tx89KSrcH6/jFDC0J+pkLKCrN4dP7G4IXieesrEbF+luOGFTC2Xy6Pzd8YMQv6ndW7SRJr8t0TCzZFtE8pZXHczN3QUg9E7/EHL+7aNX6IHMtf0+QN9vbB6vF7fCY49BKsHn+vrPD5aRMH5LOhsp6aJg91bi/1zT6KW/X4U5OTOHKQVecPDBFtXeoBq84P8Oyn1gXTQQWRoZ6R6uL44YXByVHDiqJvC/mdif3YdcC6ljEqpIQT6rzJA9hX38zeuvALuwEiVh1/7e5a3ly5iyMG9iIpsN60bUy/XKYO6c0zC7ewcMNegLDgT0oSrp9Rxle7alhQbt0/b30lE/rnUZBtXQu5YWYZG/fW8/6X4SOE3lmzm2OGFnDmhH78feHm4MX11mqbPG2uP6SUEzgu+APj+AuzrUCOdoG3KTiqJykYyq0v8NY2echNbyl1BCZFlVe0zILdV28t0BZqoj1cc/X2Ay2Tt1r1+AGOHlzA2t01wXHt0YJ/UEEWgwoyg2P1B0Up9YA1uidgaJRSD8CscSW47JAeFaXHD9YbTR/79xatxw8tF3nr3OH1/VBXHzeYHfsb+fOc8mB9P9TZR/SjKCeNR+dt5ECDh+Vbq5k5ouUC/2njShhUkMlf5pYHPxWUV9RRXlHHrHEl/Ohbw2jw+Hhiwcaor3/ZE4u58qnPdJkI5ViOC/5A/b7A7vFHGxoY6PGnJbuC4+tbL88cWL0yYESRPWJnjzVixevzc6DRQ6/M8OCfYI+EWbF9f8TkrVBTh/bGGIJ77AYmb7U2Y3ghxljDU6O9gQCcNKqIJLHKW6HDPUP1zkpl+rA+FGSltvk8Ka4kvjt5AKnJScEL1a3lpKdw9qR+QHh9P9TJo4vpn59BZa2bqSH1/YC0ZBdXHzeEBeV7eXT+BvwGZo5sCf5kVxI/PGEYq3fUBN/0ApPQvj2mhBHFOZw+ri/PLNwSsdLpmp0HWLn9AJ9vruaDNtYXUirROTD4W9X4o13cDRnHX5CVhitJIko9tU2esFJPXmYKffPSg0MVDzR6MIawGj9YtfLBBZms3HYgGPyBclKoSaX5pLqS+GTDXtJTkiKeJyBQ7hnUOysiQAMKstM4fnhhcHJYW37z3fE8ddVRbT4PwO2njOA/t0wPDlGN5qYThnHp1IEcNbh31PuTXUlccewgILzME+rSqQPJTkvm4XkbyE1PZuKA8LafO7k//fMzePBDq9f/7prdTCrNpyTPeoP80UnDqHN7ebJVrf+VpTtIdSVR2juDP767Lup+BEolOucFfwdG9TSGjON3JQmF2ZFj+Vv3+AFGFOcEg39fcPJWZGBPGJDPF9v3h5R6Invz6SkuJpXmY4w11r6tMD62rIDkJAmbsRvNo1ccyZ8vOaLdY/rnZwRLUW1JT3ExrCh6KSigtHcmvzl3fNiEs9YuP2YQN8wsC04gay0vI4VLji7FGDh+eCHJrYaXpriSuOnEMlZs289Ln29j5fYDzBpXErx/VEkuZ4zvy1MLNgVH+Hh8fl5bsYOTRhfx36eOYt2eWl5bEXUaiVIJzXnBb/f4C+xadbujeuwRO8W5aRFbMEYL/pElOZRX1uH1+YPB37rGD1adf9eBJtbsrCE1OYncjOi956OHWD3maPX9gOy0ZH551liuOW5Im8eAFdjtBXFXy05L5q7TRrVZegK4ZvoQ8jJSOHNC9DeH848cQN+8dP7ntdWAtSZQqNtOGU6jx8cj86zF3+atq6SqvpnzJg/gjPF9Gdsvl/s/WB+5XzLw3OIt/PrNLw/3x1OqW3Ns8GemuMhOS47a42/y+kh1JQV7mUW56VFq/OGlHrBm5jZ7/WyuaqDari23rvGDtfAZwJy1FRSHzNptbepQK/j75bUd/GD1no8ti14y6cn65mWw4uencFobnwrSkl1cP2MoHp9hVElO2GxjgGFFOZx7xAD+vmgLuw808cqy7RRkpTJzZCFJScIdp45k275GXvw8fCZwvdvL795ey5MLNvHx17pUtEo8Dgx+H64kIdmVRE56ctRRPY3NPtJSWn41rZdt8Pr81Df7ovb4AdbvqQ0u0BatNj+2Xx6uJOFAoydqmSdg8sBeZKclM6KNUTZO0N71BoCLjx7IiOJsLj6qNOr9t548HL8x/L+3vuSDr/Zw9qT+wVnJM0cUMnVIbx788Ovg/goAryzbTk2Tl/zMFP7vra/0OoBKOM4Lfo+fNLuEYwV/lB6/x0dGSFmkOCed6gZPcJhnyyYs4T3+wJr763bXtizJnBVZyshIdTHCXrenrRE0AFlpyXx0xwl8z74QqiKlp7h477aZXNVGqau0dyYXHVXKmyt34fEZzj9yQPA+EeHu00ezt66ZR+1ykN9v+Nsnm5lYms//nTOetbtreXlJ23sKK9UTOS/4vaHBnxJ1OGeTx0dGakvw9+9llVq228sjh67TEyo9xcXggiw7+D1kpyWTlhy9rj6p1Cr3tJ681Vqf7LSIdXPUofnRt4aTlpzE6L65EcNQJ5Xm852J/Xj8443sPtDEnLUVbNpbz7XTh3D6+BKmDOrFH99bH/aJQKmeznGJ0uz1B5dZyG2jx9/o8ZEeEtiBCUbb7F2uAm8WuemRvfkRxTms31NLdUNz1N5+QGB4YmE7PX7VOYpz03n8e1P4w/kTot7/36eOxO+He99bx5MLNtE3L53TxpUgIvzszDHsrXPz8EeRC7/NWbuHO17+QjeHUT2O44Lf7fUFe+E56SltzNz1kx7S4y/tHb7efugmLK2NKMlhc1U9O/c30jvKhd2AyYOsWa0DerV/4VZ1jhkjCqMuMwHW+b1y2iBmL9vOoo1VXDltcPBT1qTSfM6Z1I/HP94UfOMHaGj2ctcrq3h56Xb+vqj9jeSV6m4cGPzhNf5oE7isHn/Lr6Yw21pvf4v9hx+6CUtro0py8BtYsW1/m5OuwPpkMPuGY9scx6661s0nDic3PYWMFBeXHDUw7L67ThtNcpLw/95qGd751IJNVNS6GVGczf3vr48Y9aVUd+bM4LdH7ORmWD3+1mu2tK7xiwgDe2eytSoQ/C2bsLQWuGjr9vqjTt4KNWVwb63fdxN5mSn85dIjuP+iieRlhr+hl+Sl88MTh/Humj18/HUlVXVuHpm3kVPGFPPoFVNwe/389u21cWq5UofOcakTXupJxuMzYfvwQuSoHrA2Xt8a0eOPDP7BITtctVfqUd3P8cMLmTUu+iewa6cPYVBBJr9640vue389jR4fd84axZA+WfxgxhD+tXwHi+3dxJTq7pwX/J7wUT0QOXu30eOLmOUaCH6/30RswhIq2ZXEMHsFzN7ZGvyJIj3Fxf+cMYbyijqeW7yVC6eUBpe4/uGJw+ifn8EvXl8TdUc3HRGkuhvnBX9IjT9wcbZ1nb+x2R8R/IMKMnF7/VTUuiM2YWktMJFLe/yJ5aTRRZw4spDMVBe3nTw8eHtmajL/c+YY1u6u5W+fhC8K9+CHXzP51++zMmTzHaXizYHB31LqCQzHbD2yx+3xkZ4S/qsJ7Ge7pao+YhOW1gLBf7Aav+pZRISHLz+SD26fGbFd5qljizl5dDH3v/91cPTP0i37eMBeC+jOV1ZF/TSgVDw4LvibQy7uBmr0rcfyN0ap8Q+yh3Ru3dcQsQlLaxPsYYPtLa6meqb0FFfUbTBFhF+dPRYR+Plrq6lt8nDrSyvo3yuDP14wka921fDEx7odpOoeHBf8bq+fVFerGn9Ij9/j8+P1m4jg75efQZIEgj9yZc5Qx5YV8O6tM9ocN64SU//8DG4/ZQRz11Vy4aOfsqO6kfsvnMT5Rw5g1tgSHvhgPZv21se7mUo5M/hbhnNG9vibQtbiD5WanES//Ay2VDVEXZkzlIhE3bBcJb6rpg1mTN9cvtpVw80nDmOKvRnNr84eS2pyEne/ulK3fFRx57zg94TP3IXwGn9wE5bUyDV2BhVksqUDPX7lXMmuJP586RHcfsoIfnRSywXg4tx0fnr6aD7duI/nP9vazjMoFXvOC/6QUT1ZqS6SBGoaW3r8bk/4JiyhBvbOYmtVvQa/aldZYTa3nDQ8YnLexUeVMn1YH37z1ldsr25Z/uHzzfu45LFPKa+o6+qmKodyVPB77fp9oMcvIvZmLJE9/ow2evzVDR721rnbLfUoFY2IcM954wG465VVGGNYvLGKK5/6jEUbq7j9nyt05I/qEo4K/mb7jyp0kxVr2YbIGn/ri7tgTeIC8PqN9vjVYRnQK5OfnjGaBeV7+dm/V3P105/TNy+d/z17LCu3H+ChuZGrgCrV2RyVXoEyTlpIGaf1mvyNzdEv7kJL8Acep9ThuPTogfxn1S6eW7yVYUXZPP+DqRTlpLNsSzV/mVPOSaOKGT9AR4Sp2HFUjz+wJk/o5iitV+hsbGNUD7Ssyx94nFKHQ0T44wUT+f70Ibzwg2OC22/+6qxx9MlO47Z/rgh+8lQqFhwV/M128IcutZCb3rrUYx0TrdSTk54SXGq5vQlcSh1M37wMfnbmmLCNePIyU/j9+RMor6jjHl3tU8WQo4Lf7bV6UWlhwR9+cbdlHH/0X01gUxYt9ahYmDGikKumDebphZuZu64i3s1RCcphwR9Z48/NSGF/Q8dG9UDL0g1a6lGxctdpoxhZnMMdL69kb50bn9/wwmdbOfm+eXz41Z54N08lAIcFv93jDynjFOWmUef20tBslXuCPf42NkkP1Pm1x69iJT3FxYOXHEFNk4cfPreMsx9awN2vrmJ7dQO3vbQibA6AUofDWcEfZVRP4MJaRY0bOHiPf1pZH4YVZVPSanVGpTrTyJIcfnraKBZv2sfe2mb+dPEk3vnxDPwGfvyijvdX34yj6hXRSj3FudbFtYpaN4P7ZAUv7qa1sdb+sWUFfHD7zBi3VCm4ctpgRhTnMLE0n6w060/1N98dzy0vLOeBD9Zzx6mj4txC1VM5q8cfvLgbUuqxe/x77M2ym+y1+EWk6xuoVAgRYdqwPsHQBzhrYj8uPqqUv360gfnrK+PYOtWTOSz4I2fuhvb4wZrAFW0op1LdxS++M5bhRdnc+tIKdh1ojHdzVA/kzOAPKePkZaSQmpxERViPX4NfdV8ZqS4evvxI3B4fNz+/XOv96pA5MvhDJ3CJCEU5aS09/ii7bynV3ZQVZnPPeRNYuqWa3729liaPj+Vbq3lu8RZ27tdPAap9Mb24KyL5wBPAOMAA1wDrgJeAwcBm4EJjTHUs2xHg9kTW+AGKctJa1fg1+FX3952J/ViyeR9PLNjEM4s24/FZG7yMKM7mXzcdF3ZtQKlQsf4/40/AO8aY80UkFcgEfgp8aIy5R0TuAu4C7oxxO4DopR6wNsn42l4Lvcnjb3PWrlLdzU/PGI2IkJ7iYlJpHl6/4ZYXlnPH7C946NLJOkhBRRWz4BeRPGAGcBWAMaYZaBaRs4ET7MOeAT4izsFflJPGgvK9gF3qaWMMv1LdTVqyi1+eNTbsth3Vjfz27bU8On8jN8wsi1PLVHcWy67tEKAS+JuILBeRJ0QkCyg2xuyyj9kNFEd7sIhcJyJLRGRJZWXnDFtze32kJkcO1SzKTae2yUtjs88q9bQxa1epnuC6GUM5Y0Jffv/OWh3yqaKKZfAnA5OBh40xRwD1WGWdIGPtOh1152ljzGPGmCnGmCmFhYWd0iC3xx91YlZRTmBIZxONHl/U/XaV6ilEhD+cP4ERxTnc/PwyNlbqlo4qXCyDfzuw3Riz2P5+NtYbwR4R6Qtg/7fLliC09tuNDPVie/mFilo3TTqOXyWAzNRkHv/eFJJdSXz/70s40Og5+IOUY8Qs+I0xu4FtIjLSvukk4EvgdeBK+7Yrgddi1YbW3F5f9B6/PYlrT00TTV69uKsSQ2nvTB6+bDJbqxq45YXl+PxRP1wrB4r1qJ4fAc/ZI3o2Aldjvdn8U0SuBbYAF8a4DUHNXn/YrN2A4pCF2nTmrkokU4cW8OtzxnH3q6s4/ndzKO2dSf9eGVw0pZSpQwvi3TwVJzENfmPMCmBKlLtOiuXrtsXt9ZPqigz+/MwUUl1J7Kltosmr4/hVYrnk6IEkCXxSXsXO/Y3MWVvB26t288/rj9W9fR3KUTM83F5/2Fr8ASJCYU4a2/c1Ykz0/XaV6skuOmogFx01ELAGMZz70EKueeZz/v3D4+ifnxHn1qmu5qhittsTvcYPVp1/y756IPp+u0oliqKcdJ666iiamn1c+/TnYVuPKmdwVvB7ow/nBKvOv6XK2tlIe/wq0Y0syeGvl0+mvKKOm55bRrNXF3pzEgcGf/RQL8pNo7bJ2n4xI9VRvxblUMcPL+Q33x3Px1/v5c5XVmJNq1FO4LAavy/qqB5oGcsPWupRznHhlFL2HGji3vfXU5KXzp2zdFcvJ3BW8LcxcxdaZu8CUS8AK5Wobv7WMHbVNPHwRxvw+Q3XHDeEkjzdUzqROSr4m33tlXq0x6+cSUT49dnjaGr28dj8jTzx8UZmjijkxhOGcfSQ3vFunooBRxWz2xvVE9iCEfTirnIeV5Jw30WTmHfHCdx0wjC+3FXD5U8s5hN71VqVWJwV/O2M6glsug7a41fONaggi/86dSTv3jqDIX2y+MHfl7Bsa5fsk6S6kGOC3xjTbvD3ykwhxWUt16zBr5wuPzOVZ689msKcNK566jO+2lUT7yapTuSY4G+2N6Ru68Kttfeu1evXRdqUsq57/ePaqWSmJnPFk4spr9DlnROFYxKurd23QgVW6dT1+JWylPbO5B/fnwrAZU98ypaq+ji3SHUG5wS/pwPBbw/p1B24lGoxrCib575/DM1eP5c+vpjt1Q3xbpL6hpwT/F4fQJvDOcGaxOVKkmCtXyllGVmSw7PXTqW2ycM5Dy1k9tLt+HV9/x7LQcEfqPG3/SNfOKWUn54+OmJPXqUUjOufx0vXH8uAXhn818tfcO7DC/li2/54N0sdBscEf3MHavzj+udx7fQhXdUkpXqc0X1zefXGadx7wUR27m/kgkcWMWftnng3Sx0ixwR/oMef2k7wK6UOLilJOO/IAbx/2wxGluRw/bNLeW/N7ng3Sx0Cx6Sg23PwGr9SquPyM1P5x/enMrZfHjc9t4z/rNoV7yapDnJO8Heg1KOUOjR5GSk8e+3RTCrN5+bnl/HK0u3xbpLqAMekYEvwa49fqc6Uk57CM9cczbFlBfzk5S/4+6LN8W6SOggHBb9d6tFZuUp1uqy0ZJ688ihOGVPMz19bw1/mfK0bu3RjjknBjkzgUkodvvQUF3+9bDLnTOrHH99bz5V/+5w9NU3xbpaKwjEpqKUepWIvxZXE/RdN4tdnj+WzTVWc+sB83taLvt1Oh4JfRLJEJMn+9wgROUtEUmLbtM7VHJy565j3OqXiQkS44tjBvHXL8QzsncmNzy3jobnlWvrpRjqagvOBdBHpD7wHXAE8HatGxUJHZu4qpTpPWWE2s2+YxjmT+vGHd9fx89fW4NNlHrqFjm69KMaYBhG5FvirMeb3IrIihu3qdMEJXC4NfqW6SmpyEvddOIni3HQenb+RitomHrjoCDJ0Bdy46mgKiogcC1wGvGXf1qPOnNvrw5UkJGvwK9WlkpKEu08fzc/PHMN7X+7hksc/ZW+dO97NcrSOpuCtwN3Av4wxa0RkKDA3Zq2KAben7d23lFKxd830ITx82ZGs3V3DuX/9hA2VurFLvHQoCY0x84wxZxljfmdf5N1rjLklxm3rVO1tu6iU6hqzxpXw4nXH0tjs49yHPuH9L3WBt3jo6Kie50UkV0SygNXAlyJyR2yb1rncXp8O5VSqG5hUms+/bjqOgQWZ/ODvS/j1m18GV89VXaOjXeAxxpga4BzgbWAI1sieHsPt9euIHqW6idLembxy4zSumjaYJxds4oJHFrJzf2O8m+UYHU3CFHvc/jnA68YYD9CjxmVpjV+p7iUt2cUvzxrLI5dPZkNlPWf9ZQFLNu+Ld7McoaNJ+CiwGcgC5ovIIKAmVo2KhWafX0s9SnVDs8b15d8/nEZ2WjKXPP4pL362Nd5NSngdvbj7oDGmvzHmdGPZApwY47Z1KqvGrz1+pbqjYUU5vPbD6RwztIC7Xl3F//evVVr3j6GOXtzNE5H7RGSJ/XUvVu+/x3B7/Lr7llLdWF5mCn+76iiunzmU5xZv5eLHFukibzHS0SR8CqgFLrS/aoC/xapRsaDDOZXq/pJdSdx92mgeunQya3fXcuafF7Bww954NyvhdDQJy4wxvzDGbLS/fgUM7cgDRcQlIstF5E37+yEislhEykXkJRFJPdzGHwodzqlUz3HGhL78+4fHkZOezGVPLOa+99bh9Wnpp7N0NPgbRWR64BsROQ7o6NirHwNfhXz/O+B+Y8wwoBq4toPP843ocE6lepYRxTm8cfN0zps8gAfnlHPp44t1yGcn6WgS3gA8JCKbRWQz8Bfg+oM9SEQGAGcAT9jfC/AtYLZ9yDNYQ0RjTodzKtXzZKUl88cLJnL/RRNZvfMAZzz4MXPXVsS7WT1eR0f1fGGMmQhMACYYY47ACvCDeQD4byDwGa0A2G+M8drfbwf6R3ugiFwXuJhcWVnZkWa2S0s9SvVc5x4xgDd/NJ2SvAyufvpzfvufr/Bo6eewHVIX2BhTY8/gBbi9vWNF5Eygwhiz9HAaZox5zBgzxRgzpbCw8HCeIkyzXtxVqkcbWpjNv26axmVTB/Lo/I2c/8gitlTVx7tZPdI3SUI5yP3HAWfZpaEXsT4h/AnIF5HAPgADgB3foA0dpjV+pXq+9BQX/3fueP562WQ2VdZxxoML+PfyLomQhPJNkrDdJRuMMXcbYwYYYwYDFwNzjDGXYS3nfL592JXAa9+gDR3i9fnx+g2pLi31KJUITh/fl//8+HhGleRw60sruPXF5Rxo9MS7WT1Gu8EvIrUiUhPlqxbod5iveSdwu4iUY9X8nzzM5+mwZp9uu6hUohnQK5MXrzuG204ewRsrdzHrgfksLNcx/x3RbhIaY3KMMblRvnKMMR3dthFjzEfGmDPtf280xhxtjBlmjLnAGBPzrXjcHjv4tcavVEJJdiXx45OH8+qN08hIcXHpE4v51RtraPL44t20bs0RSRjcaF1H9SiVkCaW5vPWLcfzvWMH8bdPNnP6gx+zYtv+eDer23JI8Fvv/trjVypxZaS6+N+zx/GPa6fS2OzjvIcX8od31wb//lULRyRhsMevNX6lEt704X1459YZnHtEfx6au4Hv/HkBK7fvj3ezuhVHJGFLjV9LPUo5QV5GCn+8YCJ/u/ooahq9nPvXhdzz9lqt/dscEfzNPi31KOVEJ44s4r3bZ3D+5AE8Mm8Dsx6Yz6INVfFuVtw5Igl1VI9SzpWbnsLvzp/A89+fit/AJY9/yp2zV7K/oTneTYsbRyRhoMavG7Eo5VzThvXh3VtncP2Mocxetp2T75vHayt2YEyP2j68UzgiCVtG9WiNXykny0h1cffpo3nj5un075XJj19cwRVPfsbGyrp4N61LOST4dVSPUqrFmH65vHrjNP737LF8sW0/sx74mHvfW+eYi7+OSEKt8SulWnMlCd87djAf/tdMzpjQlz/PKefk++bx7prdCV/+cUQSaqlHKdWWopx07r9oEi/84BgyU11c/+xSvvfUZ5RXJG75xyHBr6UepVT7ji0r4K1bjufnZ45hxdb9zHpgPr9+88uEXPXTEUnYslaPI35cpdRhSnElcc30Icy94wQumDKApz7ZxIl//Ih/fLoloTZ7d0QSBodzuhzx4yqlvqE+2Wn89rsTeOPm6QwryuZn/17NaX/6mLnrKhKi/u+IJLT2203C2utdKaU6Zlz/PF667hgeufxIPD4/V//tc7731Ges3nEg3k37RpwR/B6/Tt5SSh0WEWHWuBLeu20mPz9zDKt2HODMPy/g1heXs21fQ7ybd1gckYZur19H9CilvpHUZKv+P++OE7nxhDLeXr2bb937Eb98fQ1762K+n1Snckjw+/TCrlKqU+RlpHDnrFF8dMcJnDd5AH9ftJkZv5/Lfe+t6zEjgByRhm6vX4dyKqU6Vd+8DO45bwLv3z6TE0YW8uCccmb8fi4PzS2n3u2Nd/Pa5Yg0dHu01KOUio2ywmz+etmRvPmj6Rw5qBd/eHcdx/9+Lo/O20BDc/d8A3BG8GupRykVY+P65/HUVUfxyo3TGNsvl9++vZbjfzeXx+Zv6HafAByRhs1evwa/UqpLHDmoF89eO5XZNxzL6L65/OY/a5n+uzk8NLec2qbucQ3AEWlo1fi11KOU6jpTBvfmH9+fyis3TmNiaT5/eHcdx90zh3vfW8e++vhuAuOY4NdZu0qpeDhyUC+evvpoXr/5OKaV9eHPc8o57p45/O8bX7Jjf2Nc2pQcl1ftYm6vT0f1KKXiasKAfB654ki+3lPLwx9t4JlFm/n7os2cNbEf188sY2RJTpe1xRFpaI3qccSPqpTq5oYX53DfRZOYd8cJXHHsIN5evZtTH5jPlU99xoKv93bJWkCOSEOduauU6m4G9MrkF98Zy8K7vsVPThnBmp01XP7kYk5/cAGzl24P7iMSCw4Jfh3OqZTqnnplpfKjk4az4M4T+f15E/D6/PzXy19w3D1z+dMHX1MdgwvBjkhDnbmrlOru0lNcXHhUKe/dNoNnrz2a8f1z+dOH69kfg2UgEv7irjHGHsevpR6lVPcnIhw/vJDjhxey+0ATJXnpnf4aCd8Nbvbp7ltKqZ4pFqEPDgh+3XZRKaXCJXwauj0a/EopFSrh0zAwJEpr/EopZXFA8Ns9fh3Vo5RSgBOCX0s9SikVJmZpKCKlIjJXRL4UkTUi8mP79t4i8r6IfG3/t1es2gBa6lFKqdZi2Q32Aj8xxowBjgF+KCJjgLuAD40xw4EP7e9jRkf1KKVUuJiloTFmlzFmmf3vWuAroD9wNvCMfdgzwDmxagNYm7CA1viVUiqgS9JQRAYDRwCLgWJjzC77rt1AcSxfu6XHr6UepZSCLgh+EckGXgFuNcbUhN5nrPVHo65BKiLXicgSEVlSWVl52K/fUuPXHr9SSkGMg19EUrBC/zljzKv2zXtEpK99f1+gItpjjTGPGWOmGGOmFBYWHnYbAqN6UjX4lVIKiO2oHgGeBL4yxtwXctfrwJX2v68EXotVG0BLPUop1VosV+c8DrgCWCUiK+zbfgrcA/xTRK4FtgAXxrANWupRSqlWYhb8xpgFgLRx90mxet3WdOauUkqFS/g0DNb4XQn/oyqlVIckfBo2+3wkJwnJGvxKKQU4IPjdHr/W95VSKkTCJ6K1366O6FFKqQAHBL9Pe/xKKRUi4RPR7fXr5C2llAqR8ImoNX6llAqX8IlolXq0xq+UUgEOCH7t8SulVKiET0RrVE/C/5hKKdVhCZ+IzV6/lnqUUipEwge/DudUSqlwCZ+IWuNXSqlwCZ+Ibo+O41dKqVAJn4g6nFMppcI5IPi11KOUUqESPhF1OKdSSoVL6ET0+vz4/EZLPUopFSKhg7/ZF9hoPaF/TKWUOiQJnYiBbRc1+JVSqkVCJ2LLRuta6lFKqYAED34foD1+pZQKldCJGOjx6wQupZRqkdCJ2FLj11KPUkoFJHbwa6lHKaUiJHQiBi/uavArpVRQQidis47qUUqpCAkd/FrqUUqpSAmdiFrqUUqpSAmdiMFRPVrqUUqpoMQOfi31KKVUhIRORJ3ApZRSkRI6EbXGr5RSkRI6Ed0eq9ST6kroH1MppQ5JQidiYNtFEYl3U5RSqttwRPArpZRqkdCpaO23q0M5lVIqVFyCX0Rmicg6ESkXkbti9Tpur097/Eop1UqXp6KIuICHgNOAMcAlIjImFq+lpR6llIoUj1Q8Gig3xmw0xjQDLwJnx+KF3B4/qboWv1JKhUmOw2v2B7aFfL8dmNr6IBG5DrgOYODAgYf1Qr0yU9ABPUopFS4ewd8hxpjHgMcApkyZYg7nOf5wwcRObZNSSiWCeJR6dgClId8PsG9TSinVBeIR/J8Dw0VkiIikAhcDr8ehHUop5UhdXuoxxnhF5GbgXcAFPGWMWdPV7VBKKaeKS43fGPMf4D/xeG2llHI6HeSulFIOo8GvlFIOo8GvlFIOo8GvlFIOI8Yc1tyoLiUilcCWVjfnAQc6cFsfYG+MmnYw0drTFc/R0ccc7Lj27m/rvo6cl55+Tg73eTrymHidE4jfeenu56Qjx3XXv5VBxpjCiFuNMT3yC3isg7ct6U5t7Irn6OhjDnZce/e3dV9HzktPPyexPC/xOifxPC/d/ZzE87zE6pz05FLPGx28LZ46oz2H8xwdfczBjmvv/rbu6+7npbPaEqvzoueka5/HkX8rPaLU802IyBJjzJR4t0O10HPSPel56X5idU56co+/ox6LdwNUBD0n3ZOel+4nJuck4Xv8Simlwjmhx6+UUiqEBr9SSjmMBr9SSjmMo4NfREaLyCMiMltEbox3exSIyDki8riIvCQi3453e5RFRIaKyJMiMjvebXEyEckSkWfsv5HLDvd5emzwi8hTIlIhIqtb3T5LRNaJSLmI3NXecxhjvjLG3ABcCBwXy/Y6QSedk38bY34A3ABcFMv2OkUnnZeNxphrY9tSZzrE8/NdYLb9N3LW4b5mjw1+4GlgVugNIuICHgJOA8YAl4jIGBEZLyJvtvoqsh9zFvAWuj9AZ3iaTjgntp/Zj1Pf3NN03nlRne9pOnh+sLaq3WYf5jvcF+y2m60fjDFmvogMbnXz0UC5MWYjgIi8CJxtjPktcGYbz/M68LqIvAU8H8MmJ7zOOCciIsA9wNvGmGUxbrIjdNbfioqNQzk/wHas8F/BN+i49+QefzT9aXk3BOuX1L+tg0XkBBF5UEQeRXv8sXJI5wT4EXAycL6I3BDLhjncof6tFIjII8ARInJ3rBun2jw/rwLnicjDfIPlHXpsj78zGGM+Aj6KczNUCGPMg8CD8W6HCmeMqcK67qLiyBhTD1z9TZ8n0Xr8O4DSkO8H2Lep+NFz0j3peeneYnp+Ei34PweGi8gQEUkFLgZej3ObnE7PSfek56V7i+n56bHBLyIvAIuAkSKyXUSuNcZ4gZuBd4GvgH8aY9bEs51Ooueke9Lz0r3F4/zoIm1KKeUwPbbHr5RS6vBo8CullMNo8CullMNo8CullMNo8CullMNo8CullMNo8KseTUTquvj1Fnbx6+WLyE1d+Zoq8WnwKxVCRNpdv8oYM62LXzMf0OBXnUqDXyUcESkTkXdEZKmIfCwio+zbvyMii0VkuYh8ICLF9u2/FJFnReQT4Fn7+6dE5CMR2Sgit4Q8d5393xPs+2eLyFoRec5eUhoROd2+bam9+uubUdp4lYi8LiJzgA9FJFtEPhSRZSKySkTOtg+9BygTkRUi8gf7sXeIyOcislJEfhXL36VKUMYY/dKvHvsF1EW57UNguP3vqcAc+9+9aJmt/n3gXvvfvwSWAhkh3y8E0oA+QBWQEvp6wAnAAazFs5KwptxPB9KxltMdYh/3AvBmlDZehbXUbm/7+2Qg1/53H6AcEGAwsDrkcd8GHrPvSwLeBGbE+zzoV8/6cvSyzCrxiEg2MA142e6AgxXgYIX0SyLSF0gFNoU89HVjTGPI928ZY9yAW0QqgGKsoA71mTFmu/26K7BCug7YaIwJPPcLwHVtNPd9Y8y+QNOB34jIDMCPtfZ6cZTHfNv+Wm5/nw0MB+a38RpKRdDgV4kmCdhvjJkU5b4/A/cZY14XkROwevYB9a2OdYf820f0v5WOHNOe0Ne8DCgEjjTGeERkM9anh9YE+K0x5tFDfC2lgrTGrxKKMaYG2CQiF4C1laOITLTvzqNlTfMrY9SEdcDQkK30OrphfB5QYYf+icAg+/ZaICfkuHeBa+xPNohIf90TVx0q7fGrni5TREJLMPdh9Z4fFpGfASnAi8AXWD38l0WkGpgDDOnsxhhjGu3hl++ISD3Wuuod8RzwhoisApYAa+3nqxKRT0RkNdY+xHeIyGhgkV3KqgMuByo6+2dRiUuXZVaqk4lItjGmzh7l8xDwtTHm/ni3S6kALfUo1fl+YF/sXYNVwtF6vOpWtMevlFIOoz1+pZRyGA1+pZRyGA1+pZRyGA1+pZRyGA1+pZRyGA1+pZRymP8fJ2ynnnWmz70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5f8730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "------------------------------\n",
      "1         Trainable params\n",
      "6         Non-trainable params\n",
      "7         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce553efb77c4932ba701e47ee06edca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=34` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-16.0098)\n"
     ]
    }
   ],
   "source": [
    "# early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
    "# trainer = Trainer(max_epochs=100, callbacks=[early_stop_callback])\n",
    "# # trainer = Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, mode='max')])\n",
    "trainer.fit(model, train_dataloaders=dataloader)\n",
    "\n",
    "print(model.final_bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-settlement",
   "metadata": {},
   "source": [
    "So, if everything worked correctly, the optimizer should have converged on `final_bias = 16.0019` after **34** steps, or epochs. **BAM!**\n",
    "\n",
    "Lastly, let's graph the output from the optimized neural network and see if it's the same as what we started with. If so, then the optimization worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the different doses through the neural network\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## set the style for seaborn so that the graph looks cool.\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values.detach(), ## NOTE: we call detach() because final_bias has a gradient\n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "## now label the y- and x-axes.\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n",
    "## lastly, save the graph as a PDF.\n",
    "# plt.savefig('BasicLightningTrain_optimized.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-broadcast",
   "metadata": {},
   "source": [
    "And we see that the optimized model results in the same graph that we started with, so the optimization worked as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-narrative",
   "metadata": {},
   "source": [
    "# Triple BAM!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
