{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first goal is to import raw data from Matlab files and coerce to df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Matlab files\n",
    "file_biomass = r'C:\\Users\\natha\\Desktop\\bootcamp_repo-1\\NW_Atlantic_Fishery_Sustainability\\data\\raw\\biomass_abund.mat'\n",
    "mat_biomass = io.loadmat(file_biomass)\n",
    "file_landings = r'C:\\Users\\natha\\Desktop\\bootcamp_repo-1\\NW_Atlantic_Fishery_Sustainability\\data\\raw\\landings.mat'\n",
    "mat_landings = io.loadmat(file_landings)\n",
    "file_ecosystem = r'C:\\Users\\natha\\Desktop\\bootcamp_repo-1\\NW_Atlantic_Fishery_Sustainability\\data\\raw\\metadata_ecosystem.mat'\n",
    "mat_ecosystem = io.loadmat(file_ecosystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coerce mat_biomass to df_biomass\n",
    "remove_keys = ['__header__', '__version__', '__globals__'] # download data irrelevant to data analysis\n",
    "for key in remove_keys:\n",
    "    mat_biomass.pop(key) # remove these keys from the imported Matlab dictionary\n",
    "\n",
    "for key in list(mat_biomass.keys()):\n",
    "    if len(mat_biomass[key])==1:\n",
    "        mat_biomass[key] = mat_biomass[key][0] # reassign ndarray as value, dropping dtype information\n",
    "\n",
    "df_biomass = pd.DataFrame.from_dict(mat_biomass, orient= 'index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coerce mat_landings to df_landings\n",
    "remove_keys = ['__header__', '__version__', '__globals__'] # download data irrelevant to data analysis\n",
    "for key in remove_keys:\n",
    "    mat_landings.pop(key) # remove these keys from the imported MATLAB dictionary\n",
    "\n",
    "\n",
    "for key in list(mat_landings.keys()):\n",
    "    if len(mat_landings[key])==1:\n",
    "        mat_landings[key] = mat_landings[key][0] # reassign ndarray as value, dropping dtype information\n",
    "\n",
    "df_landings = pd.DataFrame.from_dict(mat_landings, orient= 'index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coerce mat_ecosystem to df_ecosystem\n",
    "remove_keys = ['__header__', '__version__', '__globals__'] # download data irrelevant to data analysis\n",
    "for key in remove_keys:\n",
    "    mat_ecosystem.pop(key) # remove these keys from the imported MATLAB dictionary\n",
    "\n",
    "df_ecosystem = pd.DataFrame.from_dict(mat_ecosystem, orient= 'index').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our second goal is to load and coerce AMO text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load AMO data, to df with read_table\n",
    "# Adapted from: https://stackoverflow.com/questions/48063620/pandas-read-csv-for-multiple-delimiters\n",
    "file_AMO = r'C:\\Users\\natha\\Desktop\\bootcamp_repo-1\\NW_Atlantic_Fishery_Sustainability\\data\\raw\\amon.sm.long.data'\n",
    "df_AMO = pd.read_table(file_AMO, delimiter='\\s+|  |    ', skiprows=1, engine='python')\n",
    "df_AMO.columns = ['Year', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice df to rows with real year value, and complete data for 12 months\n",
    "dec_check = df_AMO['Dec'] > -99 # Only rows with float type, and w/in expected value\n",
    "year_check = df_AMO['Year'].str.len() == 4 # Only rows where Year column is a 4 digit year string\n",
    "df_AMO = df_AMO[dec_check & year_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our third goal is to load global ocean temperature anomally data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aravg.ann.ocean.00N.30N.v4.0.1.201711.asc', 'aravg.ann.ocean.00N.90N.v4.0.1.201711.asc', 'aravg.ann.ocean.20N.90N.v4.0.1.201711.asc', 'aravg.ann.ocean.20S.20N.v4.0.1.201711.asc', 'aravg.ann.ocean.30N.60N.v4.0.1.201711.asc', 'aravg.ann.ocean.30S.00N.v4.0.1.201711.asc', 'aravg.ann.ocean.60N.90N.v4.0.1.201711.asc', 'aravg.ann.ocean.60S.30S.v4.0.1.201711.asc', 'aravg.ann.ocean.60S.60N.v4.0.1.201711.asc', 'aravg.ann.ocean.90S.00N.v4.0.1.201711.asc', 'aravg.ann.ocean.90S.20S.v4.0.1.201711.asc', 'aravg.ann.ocean.90S.60S.v4.0.1.201711.asc', 'aravg.ann.ocean.90S.90N.v4.0.1.201711.asc']\n"
     ]
    }
   ],
   "source": [
    "# List for all .asc files in timeseries folder, filter for only annual ocean data\n",
    "# Adapted from: https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
    "temperature_folder = r\"C:\\Users\\natha\\Desktop\\bootcamp_repo-1\\NW_Atlantic_Fishery_Sustainability\\data\\raw\\timeseries\" \n",
    "dir_list = pd.Series(os.listdir(temperature_folder))\n",
    "ocean_files = [file for file in dir_list if 'ann.ocean.' in file]\n",
    "print(ocean_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all timeseries files for annual ocean temperature anomalies. Landings in our fishery metadata, I have searched for latitude of each:\n",
    "\n",
    "Long_Island_Sound   41.0748° N\n",
    "\n",
    "Georges_Bank    40.8155° N\n",
    "\n",
    "Gulf_of_Maine   43.1336° N\n",
    "\n",
    "Mid_Atlantic_Bight  39° 25' 1.2\" N\n",
    "\n",
    "Southern_New_England   40° N\n",
    "\n",
    "https://www.fisheries.noaa.gov/new-england-mid-atlantic/commercial-fishing/southern-new-england-exemption-area\n",
    "\n",
    "Chesapeake_Bay  37.5214° N\n",
    "\n",
    "Narragansett_Bay    41.6220° N\n",
    "\n",
    "Hudson_River (estuary)  40°42' N\n",
    "\n",
    "Connecticut_Shoreline   41.2700° N\n",
    "\n",
    "Delaware_Bay    39.1202° N\n",
    "\n",
    "Ambrose_Channel 40.488215° N\n",
    "\n",
    "It could be considered to subset data for the latitudes above, however this is global data over the latitude range. Oceans other than the Atlantic are in all dataset, so the decision made is to select global temperature anomalies for full range of latitude (90°S to 90°N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_file = [file for file in ocean_files if '90S.90N' in file] # select file for full latitude range\n",
    "\n",
    "df_ocean_temp = pd.read_table(f'{temperature_folder}\\{ocean_file[0]}', delimiter='\\s+|   |    ', skiprows=0, engine='python')\n",
    "# Adapted from: https://datascientyst.com/reset-column-names-index-pandas/\n",
    "df_ocean_temp = df_ocean_temp.T.reset_index().T # move first row of data from column names into first row of df\n",
    "df_ocean_temp[0] = df_ocean_temp[0].astype('int')\n",
    "df_ocean_temp.columns = ['year', 'anomaly of temperature (K)', 'total error variance (K**2)', \\\n",
    "                    'high-frequency error variance (K**2)', 'low-frequency error variance (K**2)', \\\n",
    "                    'bias error variance (K**2)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning will occur in the next notebook, for now write to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = r\"C:\\Users\\natha\\Desktop\\bootcamp_repo-1\\NW_Atlantic_Fishery_Sustainability\\data\\interim\"\n",
    "df_biomass.to_csv(fr'{csv_folder}\\biomass_data.csv')\n",
    "df_landings.to_csv(fr'{csv_folder}\\landings_data.csv')\n",
    "df_ecosystem.to_csv(fr'{csv_folder}\\ecosystem_data.csv')\n",
    "df_AMO.to_csv(fr'{csv_folder}\\AMO_data.csv')\n",
    "df_ocean_temp.to_csv(fr'{csv_folder}\\ocean_temp_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f0d103aebe82dfbb47ec724a2ca4fd3dcb0c9038207abb072b7913218171667"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
